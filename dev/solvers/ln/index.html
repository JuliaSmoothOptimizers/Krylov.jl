<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Least-norm problems · Krylov.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/style.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="Krylov.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit">Krylov.jl</span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../../api/">API</a></li><li><span class="tocitem">Krylov methods</span><ul><li><a class="tocitem" href="../spd/">Symmetric positive definite linear systems</a></li><li><a class="tocitem" href="../sid/">Symmetric indefinite linear systems</a></li><li><a class="tocitem" href="../unsymmetric/">Unsymmetric linear systems</a></li><li class="is-active"><a class="tocitem" href>Least-norm problems</a></li><li><a class="tocitem" href="../ls/">Least-squares problems</a></li><li><a class="tocitem" href="../as/">Adjoint systems</a></li><li><a class="tocitem" href="../sp_sqd/">Saddle-point and symmetric quasi-definite systems</a></li></ul></li><li><a class="tocitem" href="../../gpu/">GPU</a></li><li><a class="tocitem" href="../../matrix-free/">Matrix-free operators</a></li><li><a class="tocitem" href="../../reference/">Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Krylov methods</a></li><li class="is-active"><a href>Least-norm problems</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Least-norm problems</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaSmoothOptimizers/Krylov.jl/blob/master/docs/src/solvers/ln.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><article class="docstring"><header><a class="docstring-binding" id="Krylov.cgne" href="#Krylov.cgne"><code>Krylov.cgne</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">(x, stats) = cgne(A, b::AbstractVector{T};
                  M=opEye(), λ::T=zero(T), atol::T=√eps(T), rtol::T=√eps(T),
                  itmax::Int=0, verbose::Int=0, history::Bool=false) where T &lt;: AbstractFloat</code></pre><p>Solve the consistent linear system</p><pre><code class="language-none">Ax + √λs = b</code></pre><p>using the Conjugate Gradient (CG) method, where λ ≥ 0 is a regularization parameter. This method is equivalent to applying CG to the normal equations of the second kind</p><pre><code class="language-none">(AAᵀ + λI) y = b</code></pre><p>but is more stable. When λ = 0, this method solves the minimum-norm problem</p><p>min ‖x‖₂  s.t. Ax = b.</p><p>When λ &gt; 0, it solves the problem</p><pre><code class="language-none">min ‖(x,s)‖₂  s.t. Ax + √λs = b.</code></pre><p>CGNE produces monotonic errors ‖x-x*‖₂ but not residuals ‖r‖₂. It is formally equivalent to CRAIG, though can be slightly less accurate, but simpler to implement. Only the x-part of the solution is returned.</p><p>A preconditioner M may be provided in the form of a linear operator.</p><p><strong>References</strong></p><ul><li>J. E. Craig, <em>The N-step iteration procedures</em>, Journal of Mathematics and Physics, 34(1), pp. 64–73, 1955.</li><li>J. E. Craig, <em>Iterations Procedures for Simultaneous Equations</em>, Ph.D. Thesis, Department of Electrical Engineering, MIT, 1954.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/Krylov.jl/blob/098b3ef381241887f822a80a800ec80d6a2f9e95/src/cgne.jl#L32-L65">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Krylov.crmr" href="#Krylov.crmr"><code>Krylov.crmr</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">(x, stats) = crmr(A, b::AbstractVector{T};
                  M=opEye(), λ::T=zero(T), atol::T=√eps(T),
                  rtol::T=√eps(T), itmax::Int=0, verbose::Int=0, history::Bool=false) where T &lt;: AbstractFloat</code></pre><p>Solve the consistent linear system</p><pre><code class="language-none">Ax + √λs = b</code></pre><p>using the Conjugate Residual (CR) method, where λ ≥ 0 is a regularization parameter. This method is equivalent to applying CR to the normal equations of the second kind</p><pre><code class="language-none">(AAᵀ + λI) y = b</code></pre><p>but is more stable. When λ = 0, this method solves the minimum-norm problem</p><pre><code class="language-none">min ‖x‖₂  s.t.  x ∈ argmin ‖Ax - b‖₂.</code></pre><p>When λ &gt; 0, this method solves the problem</p><pre><code class="language-none">min ‖(x,s)‖₂  s.t. Ax + √λs = b.</code></pre><p>CGMR produces monotonic residuals ‖r‖₂. It is formally equivalent to CRAIG-MR, though can be slightly less accurate, but simpler to implement. Only the x-part of the solution is returned.</p><p>A preconditioner M may be provided in the form of a linear operator.</p><p><strong>References</strong></p><ul><li>D. Orban and M. Arioli, <em>Iterative Solution of Symmetric Quasi-Definite Linear Systems</em>, Volume 3 of Spotlights. SIAM, Philadelphia, PA, 2017.</li><li>D. Orban, <em>The Projected Golub-Kahan Process for Constrained Linear Least-Squares Problems</em>. Cahier du GERAD G-2014-15, 2014.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/Krylov.jl/blob/098b3ef381241887f822a80a800ec80d6a2f9e95/src/crmr.jl#L30-L63">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Krylov.lnlq" href="#Krylov.lnlq"><code>Krylov.lnlq</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">(x, y, stats) = lnlq(A, b::AbstractVector{T};
                     M=opEye(), N=opEye(), sqd::Bool=false, λ::T=zero(T),
                     atol::T=√eps(T), rtol::T=√eps(T), itmax::Int=0,
                     transfer_to_craig::Bool=true, verbose::Int=0, history::Bool=false) where T &lt;: AbstractFloat</code></pre><p>Find the least-norm solution of the consistent linear system</p><pre><code class="language-none">Ax + λs = b</code></pre><p>using the LNLQ method, where λ ≥ 0 is a regularization parameter.</p><p>For a system in the form Ax = b, LNLQ method is equivalent to applying SYMMLQ to AAᵀy = b and recovering x = Aᵀy but is more stable. Note that y are the Lagrange multipliers of the least-norm problem</p><pre><code class="language-none">minimize ‖x‖  s.t.  Ax = b.</code></pre><p>If <code>sqd = true</code>, LNLQ solves the symmetric and quasi-definite system</p><pre><code class="language-none">[ -F   Aᵀ ] [ x ]   [ 0 ]
[  A   E  ] [ y ] = [ b ],</code></pre><p>where E and F are symmetric and positive definite. LNLQ is then equivalent to applying SYMMLQ to <code>(AF⁻¹Aᵀ + E)y = b</code> with <code>Fx = Aᵀy</code>. Preconditioners M = E⁻¹ ≻ 0 and N = F⁻¹ ≻ 0 may be provided in the form of linear operators.</p><p>If <code>sqd = false</code>, LNLQ solves the symmetric and indefinite system</p><pre><code class="language-none">[ -F   Aᵀ ] [ x ]   [ 0 ]
[  A   0  ] [ y ] = [ b ].</code></pre><p>In this case, M can still be specified and indicates the weighted norm in which residuals are measured.</p><p>In this implementation, both the x and y-parts of the solution are returned.</p><p><strong>Reference</strong></p><ul><li>R. Estrin, D. Orban, M.A. Saunders, <em>LNLQ: An Iterative Method for Least-Norm Problems with an Error Minimization Property</em>, SIAM Journal on Matrix Analysis and Applications, 40(3), pp. 1102–1124, 2019.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/Krylov.jl/blob/098b3ef381241887f822a80a800ec80d6a2f9e95/src/lnlq.jl#L27-L66">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Krylov.craig" href="#Krylov.craig"><code>Krylov.craig</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">(x, y, stats) = craig(A, b::AbstractVector{T};
                      M=opEye(), N=opEye(), sqd::Bool=false, λ::T=zero(T), atol::T=√eps(T),
                      btol::T=√eps(T), rtol::T=√eps(T), conlim::T=1/√eps(T), itmax::Int=0,
                      verbose::Int=0, transfer_to_lsqr::Bool=false, history::Bool=false) where T &lt;: AbstractFloat</code></pre><p>Find the least-norm solution of the consistent linear system</p><pre><code class="language-none">Ax + λs = b</code></pre><p>using the Golub-Kahan implementation of Craig&#39;s method, where λ ≥ 0 is a regularization parameter. This method is equivalent to CGNE but is more stable.</p><p>For a system in the form Ax = b, Craig&#39;s method is equivalent to applying CG to AAᵀy = b and recovering x = Aᵀy. Note that y are the Lagrange multipliers of the least-norm problem</p><pre><code class="language-none">minimize ‖x‖  s.t.  Ax = b.</code></pre><p>Preconditioners M⁻¹ and N⁻¹ may be provided in the form of linear operators and are assumed to be symmetric and positive definite. If <code>sqd = true</code>, CRAIG solves the symmetric and quasi-definite system</p><pre><code class="language-none">[ -N   Aᵀ ] [ x ]   [ 0 ]
[  A   M  ] [ y ] = [ b ],</code></pre><p>which is equivalent to applying CG to <code>(AN⁻¹Aᵀ + M)y = b</code> with <code>Nx = Aᵀy</code>.</p><p>If <code>sqd = false</code>, CRAIG solves the symmetric and indefinite system</p><pre><code class="language-none">[ -N   Aᵀ ] [ x ]   [ 0 ]
[  A   0  ] [ y ] = [ b ].</code></pre><p>In this case, M⁻¹ can still be specified and indicates the weighted norm in which residuals are measured.</p><p>In this implementation, both the x and y-parts of the solution are returned.</p><p><strong>References</strong></p><ul><li>C. C. Paige and M. A. Saunders, <em>LSQR: An Algorithm for Sparse Linear Equations and Sparse Least Squares</em>, ACM Transactions on Mathematical Software, 8(1), pp. 43–71, 1982.</li><li>M. A. Saunders, <em>Solutions of Sparse Rectangular Systems Using LSQR and CRAIG</em>, BIT Numerical Mathematics, 35(4), pp. 588–604, 1995.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/Krylov.jl/blob/098b3ef381241887f822a80a800ec80d6a2f9e95/src/craig.jl#L36-L78">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Krylov.craigmr" href="#Krylov.craigmr"><code>Krylov.craigmr</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">(x, y, stats) = craigmr(A, b::AbstractVector{T};
                        M=opEye(), N=opEye(), λ::T=zero(T), atol::T=√eps(T),
                        rtol::T=√eps(T), itmax::Int=0, verbose::Int=0, history::Bool=false) where T &lt;: AbstractFloat</code></pre><p>Solve the consistent linear system</p><pre><code class="language-none">Ax + √λs = b</code></pre><p>using the CRAIG-MR method, where λ ≥ 0 is a regularization parameter. This method is equivalent to applying the Conjugate Residuals method to the normal equations of the second kind</p><pre><code class="language-none">(AAᵀ + λI) y = b</code></pre><p>but is more stable. When λ = 0, this method solves the minimum-norm problem</p><pre><code class="language-none">min ‖x‖₂  s.t.  x ∈ argmin ‖Ax - b‖₂.</code></pre><p>When λ &gt; 0, this method solves the problem</p><pre><code class="language-none">min ‖(x,s)‖₂  s.t. Ax + √λs = b.</code></pre><p>Preconditioners M⁻¹ and N⁻¹ may be provided in the form of linear operators and are assumed to be symmetric and positive definite. Afterward CRAIGMR solves the symmetric and quasi-definite system</p><pre><code class="language-none">[ -N   Aᵀ ] [ x ]   [ 0 ]
[  A   M  ] [ y ] = [ b ],</code></pre><p>which is equivalent to applying MINRES to (M + AN⁻¹Aᵀ)y = b.</p><p>CRAIGMR produces monotonic residuals ‖r‖₂. It is formally equivalent to CRMR, though can be slightly more accurate, and intricate to implement. Both the x- and y-parts of the solution are returned.</p><p><strong>References</strong></p><ul><li>D. Orban and M. Arioli. <em>Iterative Solution of Symmetric Quasi-Definite Linear Systems</em>, Volume 3 of Spotlights. SIAM, Philadelphia, PA, 2017.</li><li>D. Orban, <em>The Projected Golub-Kahan Process for Constrained, Linear Least-Squares Problems</em>. Cahier du GERAD G-2014-15, 2014.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/Krylov.jl/blob/098b3ef381241887f822a80a800ec80d6a2f9e95/src/craigmr.jl#L30-L71">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../unsymmetric/">« Unsymmetric linear systems</a><a class="docs-footer-nextpage" href="../ls/">Least-squares problems »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Tuesday 25 May 2021 14:08">Tuesday 25 May 2021</span>. Using Julia version 1.6.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
